{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and load data\n",
    "# Includes\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Setup paths containing utility\n",
    "curr_folder = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(curr_folder,'../../../app'))\n",
    "\n",
    "# Utils imports for loading data\n",
    "from utils import save_data, load_data, exists_datafolder\n",
    "from utils import load_SQuAD_train, load_SQuAD_dev\n",
    "from utils import get_foldername\n",
    "from utils_NLP import text2sentences,words2words_blanked,words2words_hashblank,words2answers\n",
    "from utils_NLP import words2text\n",
    "from utils_SQuAD import OR_arts_paragraph_fields,merge_arts_paragraph_fields\n",
    "from utils_NLP import allenNLP_classify_blanks,allenNLP_classify_blanks_fromResults\n",
    "\n",
    "# Plotting includes\n",
    "from utils_EDAplots import plotbar_train_dev,plothist_train_dev,plotbar_train_dev2,plothist_train_dev2\n",
    "\n",
    "# Stats saving stuff\n",
    "from utils_EDA import calcstats_train_dev\n",
    "\n",
    "# AllenNLP stuff\n",
    "from allennlp.predictors import Predictor\n",
    "\n",
    "# Include custom AllenNLP\n",
    "import myallennlp\n",
    "from myallennlp import *\n",
    "from myallennlp.models.simple_tagger2 import SimpleTagger2\n",
    "from myallennlp.dataset_readers import sequence_tagging2\n",
    "from myallennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "\n",
    "# Import fig stuff\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option for merging NER data into combined model\n",
    "merge_in_NER_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually test the predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2019 18:08:54 - INFO - allennlp.models.archival -   loading archive file ./model.tar.gz\n",
      "02/13/2019 18:08:54 - INFO - allennlp.models.archival -   extracting archive file ./model.tar.gz to temp dir /tmp/tmp8964gi30\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   type = default\n",
      "02/13/2019 18:08:54 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmp8964gi30/vocabulary.\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'Ntags0': 93, 'Ntags1': 7, 'do_crossentropy_weighting': True, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 72, 'input_size': 72, 'num_layers': 2, 'type': 'lstm'}, 'text_field_embedder': {'token_embedders': {'dependency_label': {'embedding_dim': 10, 'type': 'embedding', 'vocab_namespace': 'dependencies'}, 'ner_tag': {'embedding_dim': 7, 'type': 'embedding', 'vocab_namespace': 'ner'}, 'pos_tag': {'embedding_dim': 5, 'type': 'embedding', 'vocab_namespace': 'pos'}, 'tokens': {'embedding_dim': 50, 'trainable': False, 'type': 'embedding'}}}, 'type': 'simple_tagger2'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.type = simple_tagger2\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'myallennlp.models.simple_tagger2.SimpleTagger2'> from params {'Ntags0': 93, 'Ntags1': 7, 'do_crossentropy_weighting': True, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 72, 'input_size': 72, 'num_layers': 2, 'type': 'lstm'}, 'text_field_embedder': {'token_embedders': {'dependency_label': {'embedding_dim': 10, 'type': 'embedding', 'vocab_namespace': 'dependencies'}, 'ner_tag': {'embedding_dim': 7, 'type': 'embedding', 'vocab_namespace': 'ner'}, 'pos_tag': {'embedding_dim': 5, 'type': 'embedding', 'vocab_namespace': 'pos'}, 'tokens': {'embedding_dim': 50, 'trainable': False, 'type': 'embedding'}}}} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'dependency_label': {'embedding_dim': 10, 'type': 'embedding', 'vocab_namespace': 'dependencies'}, 'ner_tag': {'embedding_dim': 7, 'type': 'embedding', 'vocab_namespace': 'ner'}, 'pos_tag': {'embedding_dim': 5, 'type': 'embedding', 'vocab_namespace': 'pos'}, 'tokens': {'embedding_dim': 50, 'trainable': False, 'type': 'embedding'}}} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.type = basic\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.embedder_to_indexer_map = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.allow_unmatched_keys = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 10, 'type': 'embedding', 'vocab_namespace': 'dependencies'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.type = embedding\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.num_embeddings = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.vocab_namespace = dependencies\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.embedding_dim = 10\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.pretrained_file = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.projection_dim = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.trainable = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.padding_index = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.max_norm = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.norm_type = 2.0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.scale_grad_by_freq = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.dependency_label.sparse = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 7, 'type': 'embedding', 'vocab_namespace': 'ner'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.type = embedding\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.num_embeddings = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.vocab_namespace = ner\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.embedding_dim = 7\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.pretrained_file = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.projection_dim = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.trainable = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.padding_index = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.max_norm = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.norm_type = 2.0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.scale_grad_by_freq = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.ner_tag.sparse = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 5, 'type': 'embedding', 'vocab_namespace': 'pos'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.type = embedding\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.num_embeddings = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.vocab_namespace = pos\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.embedding_dim = 5\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.pretrained_file = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.projection_dim = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.trainable = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.padding_index = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.max_norm = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.norm_type = 2.0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.scale_grad_by_freq = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.pos_tag.sparse = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 50, 'trainable': False, 'type': 'embedding'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.type = embedding\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.num_embeddings = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.embedding_dim = 50\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.pretrained_file = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.projection_dim = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.trainable = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.padding_index = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.max_norm = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders.tokens.sparse = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 72, 'input_size': 72, 'num_layers': 2, 'type': 'lstm'} and extras {'vocab': Vocabulary with namespaces:  tokens, Size: 21902 || ner, Size: 21 || dependencies, Size: 47 || pos, Size: 17 || labels, Size: 2 || Non Padded Namespaces: {'*tags', '*labels'}}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.type = lstm\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.batch_first = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.stateful = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.bidirectional = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.dropout = 0.5\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.hidden_size = 72\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.input_size = 72\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.num_layers = 2\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.encoder.batch_first = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.do_crossentropy_weighting = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.Ntags0 = 93\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   model.Ntags1 = 7\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_hh_l0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_hh_l0_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_hh_l1\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_hh_l1_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_ih_l0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_ih_l0_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_ih_l1\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.bias_ih_l1_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_hh_l0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_hh_l0_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_hh_l1\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_hh_l1_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_ih_l0\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_ih_l0_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_ih_l1\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      encoder._module.weight_ih_l1_reverse\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      tag_projection_layer._module.bias\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      tag_projection_layer._module.weight\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_dependency_label.weight\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_ner_tag.weight\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_pos_tag.weight\n",
      "02/13/2019 18:08:54 - INFO - allennlp.nn.initializers -      text_field_embedder.token_embedder_tokens.weight\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'mytokenizer': {'type': 'word', 'word_splitter': {'ner': True, 'parse': True, 'pos_tags': True, 'type': 'whitespacy'}}, 'token_indexers': {'dependency_label': {'namespace': 'dependencies', 'type': 'dependency_label'}, 'ner_tag': {'namespace': 'ner', 'type': 'ner_tag'}, 'pos_tag': {'coarse_tags': True, 'namespace': 'pos', 'type': 'pos_tag'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'sequence_tagging2', 'word_tag_delimiter': '//'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.type = sequence_tagging2\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'myallennlp.dataset_readers.sequence_tagging2.SequenceTaggingDatasetReader'> from params {'mytokenizer': {'type': 'word', 'word_splitter': {'ner': True, 'parse': True, 'pos_tags': True, 'type': 'whitespacy'}}, 'token_indexers': {'dependency_label': {'namespace': 'dependencies', 'type': 'dependency_label'}, 'ner_tag': {'namespace': 'ner', 'type': 'ner_tag'}, 'pos_tag': {'coarse_tags': True, 'namespace': 'pos', 'type': 'pos_tag'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'word_tag_delimiter': '//'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.word_tag_delimiter = //\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_delimiter = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'namespace': 'dependencies', 'type': 'dependency_label'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.dependency_label.type = dependency_label\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer from params {'namespace': 'dependencies'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.dependency_label.namespace = dependencies\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'namespace': 'ner', 'type': 'ner_tag'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.ner_tag.type = ner_tag\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer from params {'namespace': 'ner'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.ner_tag.namespace = ner\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'coarse_tags': True, 'namespace': 'pos', 'type': 'pos_tag'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.pos_tag.type = pos_tag\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer from params {'coarse_tags': True, 'namespace': 'pos'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.pos_tag.namespace = pos\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.pos_tag.coarse_tags = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.tokens.type = single_id\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.tokens.namespace = tokens\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.tokens.lowercase_tokens = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.tokens.start_tokens = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.token_indexers.tokens.end_tokens = None\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'word', 'word_splitter': {'ner': True, 'parse': True, 'pos_tags': True, 'type': 'whitespacy'}} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.type = word\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {'word_splitter': {'ner': True, 'parse': True, 'pos_tags': True, 'type': 'whitespacy'}} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'> from params {'ner': True, 'parse': True, 'pos_tags': True, 'type': 'whitespacy'} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.word_splitter.type = whitespacy\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.from_params -   instantiating class <class 'myallennlp.data.tokenizers.word_splitter.SpacyWordSplitter'> from params {'ner': True, 'parse': True, 'pos_tags': True} and extras {}\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.word_splitter.language = en_core_web_sm\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.word_splitter.pos_tags = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.word_splitter.parse = True\n",
      "02/13/2019 18:08:54 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.word_splitter.ner = True\n",
      "02/13/2019 18:08:55 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.start_tokens = None\n",
      "02/13/2019 18:08:55 - INFO - allennlp.common.params -   dataset_reader.mytokenizer.end_tokens = None\n",
      "02/13/2019 18:08:55 - INFO - allennlp.common.params -   dataset_reader.use_spacy_directly = False\n"
     ]
    }
   ],
   "source": [
    "# Set up AllenNLP\n",
    "currmodel = os.path.join('.','model.tar.gz')\n",
    "predictor = Predictor.from_path(currmodel,predictor_name='sentence-tagger');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['___Pitch___', 'is', 'an', 'auditory', 'sensation', 'based', 'on', 'the', 'frequency', 'of', '___vibration___', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='Pitch is an auditory sensation based on the frequency of vibration.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_hashblank(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'French', 'are', 'from', 'northern', 'France', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='The French are from northern France.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_hashblank(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brain', 'is', 'an', '___organ___', 'that', 'serves', 'as', 'the', 'center', 'of', 'the', 'nervous', 'system', 'in', 'all', '___vertebrate___', 'and', 'most', '___invertebrate___', 'animals', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='The brain is an organ that serves as the center of the nervous system in all vertebrate and most invertebrate animals.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_hashblank(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['______', ',', 'the', 'function', 'of', 'the', '______', 'is', 'to', 'exert', 'centralized', 'control', 'over', 'the', 'other', 'organs', 'of', 'the', 'body', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='Physiologically, the function of the brain is to exert centralized control over the other organs of the body.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', '______', 'Death', 'ravaged', 'Europe', 'for', 'three', 'years', 'before', 'it', 'continued', 'on', 'into', '______', ',', 'where', 'the', '______', 'was', 'present', 'somewhere', 'in', 'the', 'country', '25', 'times', 'between', '______', 'to', '______', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='The Black Death ravaged Europe for three years before it continued on into Russia, where the disease was present somewhere in the country 25 times between 1350 to 1490.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', '______', 'Death', 'ravaged', 'Europe', 'for', 'three', 'years', 'before', 'it', 'continued', 'on', 'into', 'Russia', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='The Black Death ravaged Europe for three years before it continued on into Russia.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'continued', 'on', 'into', '______', ',', 'which', 'is', 'a', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='I continued on into Russia, which is a country.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'continued', 'on', 'into', 'Russia', ',', 'which', 'is', 'a', 'food', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='I continued on into Russia, which is a food.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['______', 'is', 'the', 'capital', 'of', 'Russia', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='Moscow is the capital of Russia.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Manchester', 'is', 'the', 'capital', 'of', '______', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='Manchester is the capital of England.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['______', 'is', 'the', 'capital', 'of', 'England', '.']\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(sentence='Washington is the capital of England.');\n",
    "words = results['words']\n",
    "tags = allenNLP_classify_blanks_fromResults(results,'0')\n",
    "out = words_blanked_allen = words2words_blanked(words,tags)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out sample paragraph\n",
    "p = arts[ind_ex_dev]['paragraphs'][0]\n",
    "\n",
    "# # Print all AllenNLP classifications\n",
    "# print([(a,b) for a,b in zip(p['allenNER']['words'].split(), p['allenNER']['tags'].split())])\n",
    "\n",
    "# AllenNLP results\n",
    "words = p['allenNER']['words'].split()\n",
    "# tags = p['allenNER']['tags'].split()\n",
    "# tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "tags = p['blank_classified_allen']\n",
    "\n",
    "# Ground truth\n",
    "blank_classification = p['blank_classification']\n",
    "\n",
    "\n",
    "words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "words_blanked_allen = words2words_blanked(words,tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and merge ground truth and MODEL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/davestanley/Dropbox/git/mindpocket/train_model/articles_batch2.0/entropy_93_07_model6e0c37\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frédéric_Chopin\n"
     ]
    }
   ],
   "source": [
    "# Load data containing MODEL (predictions)\n",
    "foldername = os.path.join('SQ_pp_b4m0c2')\n",
    "arts_train = load_data('train.json',foldername,prepend_data_folder=False)\n",
    "arts_dev = load_data('dev.json',foldername,prepend_data_folder=False)\n",
    "\n",
    "# All articles\n",
    "Ntrain = len(arts_train)\n",
    "Ndev = len(arts_dev)\n",
    "\n",
    "arts = arts_train + arts_dev\n",
    "print(arts[1]['title'])\n",
    "# print(arts[1]['paragraphs'][0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['qas', 'context', 'allenNER'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts[0]['paragraphs'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim down newly loaded articles to match Narticles in training set\n",
    "ind_train = slice(0,Ntrain)\n",
    "ind_dev = slice(0,Ndev)\n",
    "\n",
    "# Chosen display articles\n",
    "ind_ex_train = 1                   # Example from training set - Chopin\n",
    "ind_ex_dev = Ntrain + (467-442)    # Example from dev set - Immune system\n",
    "ind_ex_dev = Ntrain + (458-442)    # Example from dev set - Pharmacy\n",
    "ind_ex_dev = Ntrain + (456-442)    # Example from dev set - Black death\n",
    "# ind_ex_dev = 105                   # Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frédéric_Chopin\n"
     ]
    }
   ],
   "source": [
    "# Load blanks data (ground truth)\n",
    "foldername = get_foldername('sq_pp_training')\n",
    "arts3 = load_data('train.json',foldername)[ind_train] + load_data('dev.json',foldername)[ind_dev]\n",
    "print(arts3[1]['title'])\n",
    "# print(arts3[1]['paragraphs'][0]['context_blanked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching titles: 55 \n",
      "Total articles 55\n"
     ]
    }
   ],
   "source": [
    "# Make sure all titles match\n",
    "all_title_pairs = [(a1['title'],a3['title']) for a1,a3 in zip(arts,arts3)]\n",
    "titles_match_bool = [a1['title'] == a3['title'] for a1,a3 in zip(arts,arts3)]\n",
    "print(\"Matching titles: {} \\nTotal articles {}\".format(sum(titles_match_bool),len(titles_match_bool)))\n",
    "if not sum(titles_match_bool) == len(titles_match_bool):\n",
    "    raise ValueError('Articles mismatch.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ground truth blanks with original data to get full dataset\n",
    "list_of_fields = ['context_blanked','blank_classification']\n",
    "arts = merge_arts_paragraph_fields(arts,arts3,list_of_fields)\n",
    "\n",
    "# print(arts[1]['title'])\n",
    "# print(arts[1]['paragraphs'][0]['context'])\n",
    "# print(arts[1]['paragraphs'][0]['context_blanked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frédéric François Chopin (/ˈʃoʊpæn/; French pronunciation: \\u200b[fʁe.de.ʁik fʁɑ̃.swa ʃɔ.pɛ̃]; 22 February or 1 March 1810 – 17 October 1849), born Fryderyk Franciszek Chopin,[n 1] was a Polish and French (by citizenship and birth of father) composer and a virtuoso pianist of the Romantic era, who wrote primarily for the solo piano. He gained and has maintained renown worldwide as one of the leading musicians of his era, whose \"poetic genius was based on a professional technique that was without equal in his generation.\" Chopin was born in what was then the Duchy of Warsaw, and grew up in Warsaw, which after 1815 became part of Congress Poland. A child prodigy, he completed his musical education and composed his earlier works in Warsaw before leaving Poland at the age of 20, less than a month before the outbreak of the November 1830 Uprising.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts[ind_ex_train]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['qas', 'context', 'allenNER', 'context_blanked', 'blank_classification', 'blank_classified_allen'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert AllenNLP Model blanks classification into standard format\n",
    "\n",
    "# If doing merge, use unique name for this model result. Otherwise, use generic name\n",
    "if merge_in_NER_data: fieldname = 'blank_classified_allenMODEL'\n",
    "else: fieldname = 'blank_classified_allen'\n",
    "\n",
    "arts = allenNLP_classify_blanks(arts,'0',fieldname)\n",
    "arts[0]['paragraphs'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NER data and merge into arts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if merge_in_NER_data:\n",
    "    # Load data containing NEP (predictions)\n",
    "    foldername = get_foldername('sq_pp_ner')\n",
    "\n",
    "    arts_NER = load_data('train.json',foldername)[ind_train] + load_data('dev.json',foldername)[ind_dev]\n",
    "    print(arts[1]['title'])\n",
    "    # print(arts[1]['paragraphs'][0]['context'])\n",
    "\n",
    "    # Make sure all titles match\n",
    "    all_title_pairs = [(a1['title'],a3['title']) for a1,a3 in zip(arts,arts_NER)]\n",
    "    titles_match_bool = [a1['title'] == a3['title'] for a1,a3 in zip(arts,arts_NER)]\n",
    "    print(\"Matching titles: {} \\nTotal articles {}\".format(sum(titles_match_bool),len(titles_match_bool)))\n",
    "    if not sum(titles_match_bool) == len(titles_match_bool):\n",
    "        raise ValueError('Articles mismatch.')\n",
    "\n",
    "    # Convert AllenNLP Model blanks classification into standard format\n",
    "    from utils_NLP import allenNLP_classify_blanks\n",
    "    arts_NER = allenNLP_classify_blanks(arts_NER,'O','blank_classified_allenNER')\n",
    "    print(arts_NER[0]['paragraphs'][0].keys())\n",
    "\n",
    "    # Merge NER data into full dataset\n",
    "    list_of_fields = ['blank_classified_allenNER']\n",
    "    arts = merge_arts_paragraph_fields(arts,arts_NER,list_of_fields)\n",
    "    print(arts[0]['paragraphs'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR operation on blank_classified_allenMODEL and blank_classified_allenNER into blank_classified_allenMODEL\n",
    "\n",
    "if merge_in_NER_data:\n",
    "    destination_fieldname = 'blank_classified_allen'\n",
    "    arts = OR_arts_paragraph_fields(arts,['blank_classified_allenMODEL','blank_classified_allenNER'],destination_fieldname)\n",
    "\n",
    "    p = arts[0]['paragraphs'][1]\n",
    "    print(p['blank_classified_allenNER'])\n",
    "    print(p['blank_classified_allenMODEL'])\n",
    "    print(p['blank_classified_allen'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare paragraph word reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just looks at the words in the different saved fiels files to make sure all the words match up 1:1 (otherwise, this could mess up our evaluations). Not looking at blanks here at all. The next sectoin looks at the blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out sample paragraph\n",
    "p = arts[ind_ex_dev]['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AllenNLP Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "131\n",
      "The Black Death is thought to have originated in the arid plains of Central Asia, where it then travelled along the Silk Road, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on merchant ships. Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60 % of Europe 's total population. In total, the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th century. The world population as a whole did not recover to pre - plague levels until the 17th century. The plague recurred occasionally in Europe until the 19th century.\n",
      "706\n"
     ]
    }
   ],
   "source": [
    "words = p['allenNER']['words'].split()\n",
    "tags = p['allenNER']['tags'].split()\n",
    "print(len(words))\n",
    "print(len(tags))\n",
    "print(words2text(words))\n",
    "print(len(words2text(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "The Black Death is thought to have originated in the arid plains of Central Asia, where it then travelled along the Silk Road, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on merchant ships. Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60 % of Europe 's total population. In total, the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th century. The world population as a whole did not recover to pre - plague levels until the 17th century. The plague recurred occasionally in Europe until the 19th century.\n",
      "706\n"
     ]
    }
   ],
   "source": [
    "from utils_NLP import allenNLP_split_words, join_punctuation\n",
    "\n",
    "context = p['context']\n",
    "context_split = allenNLP_split_words(context)\n",
    "\n",
    "# context_reassembled = ' '.join(context_split)\n",
    "context_reassembled = words2text(context_split)\n",
    "\n",
    "print(len(context_split))\n",
    "# print(words2text(context_split))\n",
    "# print(len(words2text(context_split)))\n",
    "print(context_reassembled)\n",
    "print(len(context_reassembled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context_blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "dict_keys(['qas', 'context', 'allenNER', 'context_blanked', 'blank_classification', 'blank_classified_allen'])\n",
      "The Black Death is thought to have originated in the arid plains of ______ ______ , where it then travelled along the ______ ______ , reaching Crimea by 1343 . From there , it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on ______ ______ . Spreading throughout the Mediterranean and Europe , the Black Death is estimated to have killed 30–60 % of Europe 's total population . In total , the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th ______ . The world population as a whole did not recover to pre - plague levels until the ______ ______ . The plague recurred occasionally in Europe until the ______ ______ .\n"
     ]
    }
   ],
   "source": [
    "print(len(p['blank_classification']))\n",
    "print(p.keys())\n",
    "print(p['context_blanked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central\n",
      "Asia\n",
      "Silk\n",
      "Road\n",
      "merchant\n",
      "ships\n",
      "century\n",
      "17th\n",
      "century\n",
      "19th\n",
      "century\n"
     ]
    }
   ],
   "source": [
    "# Answers\n",
    "for i,c in enumerate(p['blank_classification']):\n",
    "    if c == 1: print(context_split[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single paragraph - Compare blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, just look at the raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out sample paragraph\n",
    "p = arts[ind_ex_dev]['paragraphs'][0]\n",
    "\n",
    "# # Print all AllenNLP classifications\n",
    "# print([(a,b) for a,b in zip(p['allenNER']['words'].split(), p['allenNER']['tags'].split())])\n",
    "\n",
    "# AllenNLP results\n",
    "words = p['allenNER']['words'].split()\n",
    "# tags = p['allenNER']['tags'].split()\n",
    "# tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "tags = p['blank_classified_allen']\n",
    "\n",
    "# Ground truth\n",
    "blank_classification = p['blank_classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Allen tags: 131. Length ground truth blanks: 131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Length Allen tags: {}. Length ground truth blanks: {}\".format(len(tags),len(blank_classification)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\t\t\t==========\n",
      "Ground truth\t\t\tPrediction\n",
      "============\t\t\t==========\n",
      "The\t\t\t\tThe\n",
      "Black\t\t\t\t______\n",
      "Death\t\t\t\t______\n",
      "is\t\t\t\tis\n",
      "thought\t\t\t\tthought\n",
      "to\t\t\t\tto\n",
      "have\t\t\t\thave\n",
      "originated\t\t\t\toriginated\n",
      "in\t\t\t\tin\n",
      "the\t\t\t\tthe\n",
      "arid\t\t\t\tarid\n",
      "plains\t\t\t\t______\n",
      "of\t\t\t\tof\n",
      "______\t\t\t\t______\n",
      "______\t\t\t\tAsia\n",
      ",\t\t\t\t,\n",
      "where\t\t\t\twhere\n",
      "it\t\t\t\tit\n",
      "then\t\t\t\tthen\n",
      "travelled\t\t\t\ttravelled\n"
     ]
    }
   ],
   "source": [
    "# Side by side compare\n",
    "\n",
    "words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "words_blanked_allen = words2words_blanked(words,tags)\n",
    "\n",
    "N=len(words_blanked_ground_truth)\n",
    "N=20\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "print(\"Ground truth\" + '\\t\\t\\t' + \"Prediction\")\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "for c,w in zip(words_blanked_ground_truth[:N],words_blanked_allen[:N]):\n",
    "    print(c + '\\t\\t\\t\\t' + w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Black Death is thought to have originated in the arid plains of ______ ______, where it then travelled along the ______ ______, reaching Crimea by 1343. From there, it was most likely carried by Oriental rat fleas living on the black rats that were regular passengers on ______ ______. Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30–60 % of Europe 's total population. In total, the plague reduced the world population from an estimated 450 million down to 350–375 million in the 14th ______. The world population as a whole did not recover to pre - plague levels until the ______ ______. The plague recurred occasionally in Europe until the ______ ______.\n",
      "Answers:\n",
      "['Central', 'Asia', 'Silk', 'Road', 'merchant', 'ships', 'century', '17th', 'century', '19th', 'century']\n"
     ]
    }
   ],
   "source": [
    "# Blanked text\n",
    "print(words2text(words_blanked_ground_truth))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,blank_classification)\n",
    "print(\"Answers:\")\n",
    "print(myanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ______ ______ is thought to have originated in the arid ______ of ______ Asia, where it then travelled along the ______ ______, reaching Crimea by ______. From there, it was most likely carried by ______ ______ ______ living on the black ______ that were regular passengers on merchant ships. Spreading throughout the ______ and Europe, the ______ ______ is estimated to have killed ______ % of Europe 's total population. In total, the ______ reduced the world population from an estimated ______ ______ down to 350–375 ______ in the 14th century. The world population as a whole did not recover to pre - plague levels until the ______ century. The ______ recurred occasionally in Europe until the 19th century.\n",
      "Answers:\n",
      "['Black', 'Death', 'plains', 'Central', 'Silk', 'Road', '1343', 'Oriental', 'rat', 'fleas', 'rats', 'Mediterranean', 'Black', 'Death', '30–60', 'plague', '450', 'million', 'million', '17th', 'plague']\n"
     ]
    }
   ],
   "source": [
    "# Blanked text\n",
    "print(words2text(words_blanked_allen))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,tags)\n",
    "print(\"Answers:\")\n",
    "print(myanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([b and t for b,t in zip(blank_classification,tags)])\n",
    "FP = sum([not b and t for b,t in zip(blank_classification,tags)])\n",
    "FN = sum([b and not t for b,t in zip(blank_classification,tags)])\n",
    "TN = sum([not b and not t for b,t in zip(blank_classification,tags)])\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "ACC2 = sum([b == t for b,t in zip(blank_classification,tags)]) / len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816793893129771\n",
      "0.816793893129771\n",
      "4\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(ACC)\n",
    "print(ACC2)\n",
    "print(TP)\n",
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36363636363636365\n",
      "0.14166666666666666\n"
     ]
    }
   ],
   "source": [
    "print(TPR)\n",
    "print(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nsentences=6\n",
      "Nsentences_from_words=6\n"
     ]
    }
   ],
   "source": [
    "Nsentences = len(text2sentences(p['context']))\n",
    "print(\"Nsentences={}\".format(str(Nsentences)))\n",
    "\n",
    "Nsentences2 = len(text2sentences(words2text(words)))\n",
    "print(\"Nsentences_from_words={}\".format(str(Nsentences2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "2.8333333333333335\n"
     ]
    }
   ],
   "source": [
    "TPpersent = TP / Nsentences2\n",
    "FPpersent = FP / Nsentences2\n",
    "\n",
    "print(TPpersent)\n",
    "print(FPpersent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single article - compare blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black_Death\n"
     ]
    }
   ],
   "source": [
    "##### Pull out sample paragraph\n",
    "a = arts[ind_ex_dev]\n",
    "print(a['title'])\n",
    "\n",
    "# AllenNLP results\n",
    "words = [w for p in a['paragraphs'] for w in p['allenNER']['words'].split()]\n",
    "# tags = [t for p in a['paragraphs'] for t in p['allenNER']['tags'].split()]\n",
    "# tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "tags = [t for p in a['paragraphs'] for t in p['blank_classified_allen']]\n",
    "\n",
    "# Ground truth\n",
    "blank_classification = [bc for p in a['paragraphs'] for bc in p['blank_classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Allen tags: 3683. Length ground truth blanks: 3683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Length Allen tags: {}. Length ground truth blanks: {}\".format(len(tags),len(blank_classification)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\t\t\t============\t\t\t==========\n",
      "Original\t\t\tGround truth\t\t\tPrediction\n",
      "========\t\t\t============\t\t\t==========\n",
      "The\t\t\t\tThe\t\t\t\tThe\n",
      "Black\t\t\t\tBlack\t\t\t\t______\n",
      "Death\t\t\t\tDeath\t\t\t\t______\n",
      "is\t\t\t\tis\t\t\t\tis\n",
      "thought\t\t\t\tthought\t\t\t\tthought\n",
      "to\t\t\t\tto\t\t\t\tto\n",
      "have\t\t\t\thave\t\t\t\thave\n",
      "originated\t\t\t\toriginated\t\t\t\toriginated\n",
      "in\t\t\t\tin\t\t\t\tin\n",
      "the\t\t\t\tthe\t\t\t\tthe\n",
      "arid\t\t\t\tarid\t\t\t\tarid\n",
      "plains\t\t\t\tplains\t\t\t\t______\n",
      "of\t\t\t\tof\t\t\t\tof\n",
      "Central\t\t\t\t______\t\t\t\t______\n",
      "Asia\t\t\t\t______\t\t\t\tAsia\n",
      ",\t\t\t\t,\t\t\t\t,\n",
      "where\t\t\t\twhere\t\t\t\twhere\n",
      "it\t\t\t\tit\t\t\t\tit\n",
      "then\t\t\t\tthen\t\t\t\tthen\n",
      "travelled\t\t\t\ttravelled\t\t\t\ttravelled\n",
      "along\t\t\t\talong\t\t\t\talong\n",
      "the\t\t\t\tthe\t\t\t\tthe\n",
      "Silk\t\t\t\t______\t\t\t\t______\n",
      "Road\t\t\t\t______\t\t\t\t______\n",
      ",\t\t\t\t,\t\t\t\t,\n",
      "reaching\t\t\t\treaching\t\t\t\treaching\n",
      "Crimea\t\t\t\tCrimea\t\t\t\tCrimea\n",
      "by\t\t\t\tby\t\t\t\tby\n",
      "1343\t\t\t\t1343\t\t\t\t______\n",
      ".\t\t\t\t.\t\t\t\t.\n"
     ]
    }
   ],
   "source": [
    "# Side by side compare\n",
    "words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "words_blanked_allen = words2words_blanked(words,tags)\n",
    "\n",
    "N=len(words_blanked_ground_truth)\n",
    "N=30\n",
    "print(\"========\" + '\\t\\t\\t' + \"============\" + '\\t\\t\\t' + \"==========\")\n",
    "print(\"Original\" + '\\t\\t\\t' + \"Ground truth\" + '\\t\\t\\t' + \"Prediction\")\n",
    "print(\"========\" + '\\t\\t\\t' + \"============\" + '\\t\\t\\t' + \"==========\")\n",
    "for o,c,w in zip(words[:N],words_blanked_ground_truth[:N],words_blanked_allen[:N]):\n",
    "    print(o + '\\t\\t\\t\\t' + c + '\\t\\t\\t\\t' + w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([b and t for b,t in zip(blank_classification,tags)])\n",
    "FP = sum([not b and t for b,t in zip(blank_classification,tags)])\n",
    "FN = sum([b and not t for b,t in zip(blank_classification,tags)])\n",
    "TN = sum([not b and not t for b,t in zip(blank_classification,tags)])\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "ACC2 = sum([b == t for b,t in zip(blank_classification,tags)]) / len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373608471354874\n",
      "0.8373608471354874\n"
     ]
    }
   ],
   "source": [
    "print(ACC)\n",
    "print(ACC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sensitivity, hit rate, recall, or true positive rate\n",
    "# TPR = TP/(TP+FN)\n",
    "# # Specificity or true negative rate\n",
    "# TNR = TN/(TN+FP) \n",
    "# # Precision or positive predictive value\n",
    "# PPV = TP/(TP+FP)\n",
    "# # Negative predictive value\n",
    "# NPV = TN/(TN+FN)\n",
    "# # Fall out or false positive rate\n",
    "# FPR = FP/(FP+TN)\n",
    "# # False negative rate\n",
    "# FNR = FN/(TP+FN)\n",
    "# # False discovery rate\n",
    "# FDR = FP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TPR)\n",
    "# print(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nsentences_from_words=126\n"
     ]
    }
   ],
   "source": [
    "Nsentences2 = len(text2sentences(words2text(words)))\n",
    "print(\"Nsentences_from_words={}\".format(str(Nsentences2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "4.182539682539683\n"
     ]
    }
   ],
   "source": [
    "TPpersent = TP / Nsentences2\n",
    "FPpersent = FP / Nsentences2\n",
    "\n",
    "print(TPpersent)\n",
    "print(FPpersent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth blanked vs predicted blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers:\n",
      "{'Silk', '1850', 'Jani', 'Smithfield', 'Alexandre', '1654', 'faster', 'Asia', 'bad', '90', 'ships', '38–41', 'century', 'corpses', 'Italian', 'atra', 'bubonic', '1350', '1.7', '1823', 'Scandinavia', 'northwestern', '1500', 'Genoese', 'significance', 'J.I.', 'dating', 'fleas', 'Miasma', '1908', 'Kong', 'France', '15', 'rats', 'trade', 'China', 'Half', 'plague', '2010', 'commonly', '1338–39', 'Justinian', 'East', 'much', 'England', 'Germany', 'theory', 'million', '1665', 'Yersin', 'percent', '2011', 'Yersinia', 'merchant', '100–106', 'anthrax', '100,000', '19th', 'infected', 'traders', '95', 'Gasquet', 'half', 'king', 'pestis', 'areas', 'branches', '40,000', 'Hong', 'Plague', '1331', '1720', 'Beg', 'marginal', 'Pontanus', '1349', 'isolated', 'form', 'amended', 'Road', 'genetic', 'October', 'Y.', 'present', 'Sicily', '1377', 'figures', 'mors', 'north', '22', 'clergy', 'air', '25', 'Central', '5', 'account', 'Russia', 'Constantinople', 'population', 'autumn', 'northwest', 'epidemiological', 'confirmed', '1347', 'heavens', '80', '17th', 'third', 'spring'}\n"
     ]
    }
   ],
   "source": [
    "# Blanked text\n",
    "# print(words2text(words_blanked_ground_truth))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,blank_classification)\n",
    "print(\"Answers:\")\n",
    "print(set(myanswers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers:\n",
      "{'Silk', 'CE', 'Sloane', '7', 'infectious', 'clades', '1850', 'society', 'Jani', 'Portugal', 'Basque', 'Mongol', 'outbreaks', 'India', 'Alexandre', 'malaise', 'Smithfield', 'Epidemics', 'Cohn', 'symptoms', 'Monks', '1576–77', '1654', '1620–21', '30–75', 'Lake', '1374', 'bites', 'pandemics', '700', 'spaced', 'Haensch', 'infections', '1593', 'Helsinki', 'Pneumonic', 'corpses', 'Italian', 'atra', 'Italy', 'bubonic', '1389–93', '1350', 'Biraben', '1.7', 'Bergen', 'disease', '1823', 'endemic', 'Minor.[citation', 'Scandinavia', '1500', 'Homs', 'Genoese', 'Domesday', '1750', 'Middle', 'buboes', 'Zoom', 'Amsterdam', 'J.I.', 'Archaeologist', 'resistant', '1893', 'Mediterranean', 'fleas', 'Miasma', 'Aleppo', 'Norway', 'rat', '50', '1908', '300,000', 'coagulation', 'France', '15', 'Nestorian', 'skin', 'rats', 'Geoffrey', 'respiratory', 'behaviour', 'epidemics', 'Netherlands', 'China', 'purpura', 'wills', 'Kaffa', 'starvation', 'Londoners', 'pits', 'plague', 'Pandemic', '1490', '450', '1628–31', '1679', 'regurgitation', 'epidemiology', 'Stockholm', 'rodents', 'Aidan', 'sputum', 'pneumonic', 'characterise', '110–120', 'Palestine', 'lymph', 'op', 'Justinian', 'Raoult', '1998', '1479–80', '1361', 'burial', 'poisoning', 'PLoS', 'Barney', 'patches', 'feeding', '1644–54', '15th', 'Twigg', 'England', '1629–1631', 'Crimea', 'Bjørgvin', 'Simond', '1625', 'Hamburg', '50,000', 'Norman', 'Germany', 'sufferers', 'siege', '14th', '1894', 'Francis', 'London', 'Sea', '1351', 'million', 'waterfront', 'typhus', '4', '1623–25', 'Black', 'Kul', 'bacteria', '1338', '1528', 'Jr.', 'extinction', 'Yersin', '1665', '2011', 'Issyk', 'Roman', '1343', 'smallpox', 'Clerkenwell', '1800', 'Europe', 'Yersinia', '1346', 'cough', 'Duncan', 'anthrax', 'outbreak', '1671', '100,000', 'Belgium', '1379–83', 'infected', '1631', '1466', '16th', 'Antioch', '1635–36', '1348–49', '95', 'blood', '1471', 'Naples', 'Gasquet', '2014', 'visitations', 'lungs', '1498', 'medieval', 'Vulgo', 'contagion', 'pestilence', 'thousand', 'pestis', '1664', '1300', '1589', 'Gaza', 'tracts', 'branches', 'enzootic', '1348', '40,000', 'Plague', 'Acre', 'vomiting', 'Death', 'Nature', 'Africa', '1649', 'Ottoman', 'epidemic', '170,000', '1331', '1720', 'marmots', 'Uganda', 'Beg', 'Poland', '1543', 'Pontanus', '1349', 'pandemic', 'Vienna', 'pathogen', 'Louis', 'septicemic', 'Graham', '1360–63', '1700–21', 'Road', 'geneticists', 'Thirty', '20', 'intravascular', 'hemorrhagic', 'genetic', 'Florence', '1603', '1330s', 'Seville', 'October', 'Y.', 'Polymerase', '1970', 'Cantor', '1701', '1656', 'Book', 'June', '1865', '1751', 'diseases', 'Oriental', 'zoologist', '1563', 'airborne', '1348–50', 'Schuenemann', 'Sicily', 'Iceland', 'Alexandria', '1377', 'Hanseatic', 'untreated', 'fever', 'Herlihy', 'Tudor', '1655', '1654–57', 'Pestilence', 'skeletons', '1636', 'Stuart', 'medical', '1450', 'Septicemic', 'nodes', 'infection', '1361–62', 'Askøy', 'mors', 'famine', 'Pathogens', 'sockets', 'farming', '1898', 'epidemiologists', '1740–42', '25', '2', 'plains', 'mechanism', 'tooth', 'Prussia', 'Central', 'replicating', 'nausea', 'hundred', 'Russia', 'Oslo', 'recurrence', '541', 'Constantinople', 'Marseille', '1345', 'mortality', '1.25', 'Ages', 'Parker', '30–60', 'genome', 'Bremen', '1369', 'Ebola', 'autumn', '10–15', 'Venice', '1709–13', 'epidemiological', 'Scott', '1347', 'heavens', '1535', 'Paris', '17th', '1691', 'pit'}\n"
     ]
    }
   ],
   "source": [
    "# Blanked text\n",
    "# print(words2text(words_blanked_allen))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,tags)\n",
    "print(\"Answers:\")\n",
    "print(set(myanswers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fract of answers blanked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fract answers blanked vs num answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pseudocode\n",
    "# For each answer, loop through the words and count the number of times it occurs.\n",
    "# Get the set of blanks booleans associated with each occurrence of that words, and calculate the\n",
    "# mean. Will do this for each word in the article, and then each article in the corpus. For each\n",
    "# article, rank the words by their proximity to 50 % \n",
    "\n",
    "myanswers_unique = list(set(words2answers(words,tags)))\n",
    "\n",
    "fracblanked = []\n",
    "numblanked = []\n",
    "for ans in myanswers_unique:\n",
    "    indices = [i for i, w in enumerate(words) if w == ans]\n",
    "    tags_curr = [tags[i] for i in indices]\n",
    "    #words_curr = [words[i] for i in indices]\n",
    "    fracblanked.append(sum(tags_curr)/len(tags_curr)*100)\n",
    "    numblanked.append(len(tags_curr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Num occurrences')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do scatter plot\n",
    "y = numblanked\n",
    "z = fracblanked\n",
    "n = myanswers_unique\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(z, y)\n",
    "\n",
    "for i, txt in enumerate(n):\n",
    "    ax.annotate(txt, (z[i], y[i]))\n",
    "plt.xlabel('Percentage of times blanked out')\n",
    "plt.ylabel('Num occurrences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fract answers blanked for all answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = {'myanswers_unique':myanswers_unique,'fracblanked':fracblanked}\n",
    "\n",
    "df = pd.DataFrame(data=d);\n",
    "\n",
    "df2 = df.sort_values(by='fracblanked',ascending=True);\n",
    "\n",
    "\n",
    "\n",
    "N=30          # of data points to show\n",
    "figure(num=None, figsize=(8, 8),facecolor='w', edgecolor='k')\n",
    "bars = (df2['myanswers_unique'].values.tolist())[0:N]\n",
    "y_pos = np.arange(len(bars))\n",
    "val = (df2['fracblanked'].values.tolist())[0:N]\n",
    "y_pos = np.arange(len(bars))\n",
    " \n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, val)\n",
    " \n",
    "# Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "\n",
    "plt.xlabel('Percentage of times blanked out')\n",
    "# Show graphic\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fractions of POS/NER tags blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-512ac7345a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     'dep':dep}\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mxlabs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(words2text(words))\n",
    "\n",
    "pos=[]\n",
    "ner=[]\n",
    "dep=[]\n",
    "for token in doc:\n",
    "    pos.append(token.pos_)\n",
    "    ner.append(token.ent_type_)\n",
    "    dep.append(token.dep_)\n",
    "\n",
    "# Build a dataframe to store everything\n",
    "d = {'ind': range(len(words)),\n",
    "     'words' : words,\n",
    "    'tags':tags,\n",
    "    'pos':pos,\n",
    "    'ner':ner,\n",
    "    'dep':dep}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "xlabs=[]\n",
    "yvals=[]\n",
    "\n",
    "# Search through keys and unique items therein, counting \"Trues\"\n",
    "keys = ['ner']\n",
    "for k in keys:\n",
    "    for item in list(set(d[k])):\n",
    "        df2 = df.loc[df[k] == item]\n",
    "        mysum = df2.sum()['tags']\n",
    "        N = len(df2)\n",
    "        \n",
    "        xlabs.append(k.upper() + ': ' + item.lower())\n",
    "        yvals.append(mysum/N*100)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.loc[df['ner'] == 'PERSON']\n",
    "df3           # Hmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'xlabs':xlabs,'yvals':yvals})\n",
    "df = df.sort_values(by='yvals',ascending=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(7,7),facecolor='w', edgecolor='k')\n",
    "bars = df['xlabs']\n",
    "y_pos = np.arange(len(bars))\n",
    "val = df['yvals']\n",
    "\n",
    "# Make fake dataset\n",
    "y_pos = np.arange(len(bars))\n",
    " \n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, val)\n",
    " \n",
    "# Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "\n",
    "plt.xlabel('% of times blanked')\n",
    "# Show graphic\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print('--------------- GROUND TRUTH ---------------')\n",
    "\n",
    "# # Pull out sample paragraph\n",
    "# for p in arts[ind_ex_dev]['paragraphs']:\n",
    "#     # # Print all AllenNLP classifications\n",
    "#     # print([(a,b) for a,b in zip(p['allenNER']['words'].split(), p['allenNER']['tags'].split())])\n",
    "\n",
    "#     # AllenNLP results\n",
    "#     words = p['allenNER']['words'].split()\n",
    "#     # tags = p['allenNER']['tags'].split()\n",
    "#     # tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "#     tags = p['blank_classified_allen']\n",
    "\n",
    "#     # Ground truth\n",
    "#     blank_classification = p['blank_classification']\n",
    "\n",
    "#     words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "#     words_blanked_allen = words2words_blanked(words,tags)\n",
    "#     words_hash_ground_truth = words2words_hashblank(words,blank_classification)\n",
    "#     words_hash_allen = words2words_hashblank(words,tags)\n",
    "    \n",
    "    \n",
    "#     # Blanked text\n",
    "#     print(words2text(words_hash_ground_truth))\n",
    "\n",
    "#     # Answers    \n",
    "#     myanswers = words2answers(words,blank_classification)\n",
    "#     print(\"Answers:\")\n",
    "#     print(myanswers)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- MY MODEL ---------------\n",
      "The ___Black___ ___Death___ is thought to have originated in the arid ___plains___ of ___Central___ Asia, where it then travelled along the ___Silk___ ___Road___, reaching Crimea by ___1343___. From there, it was most likely carried by ___Oriental___ ___rat___ ___fleas___ living on the black ___rats___ that were regular passengers on merchant ships. Spreading throughout the ___Mediterranean___ and Europe, the ___Black___ ___Death___ is estimated to have killed ___30–60___ % of Europe 's total population. In total, the ___plague___ reduced the world population from an estimated ___450___ ___million___ down to 350–375 ___million___ in the 14th century. The world population as a whole did not recover to pre - plague levels until the ___17th___ century. The ___plague___ recurred occasionally in Europe until the 19th century.\n",
      "Answers:\n",
      "['Death', 'million', '30–60', 'Silk', 'Black', 'Road', 'Oriental', 'plains', 'rats', '450', 'Central', 'Mediterranean', 'fleas', 'rat', 'plague', '17th', '1343']\n",
      "The ___plague___ disease, caused by ___Yersinia___ ___pestis___, is ___enzootic___ ( commonly present ) in populations of ___fleas___ carried by ground ___rodents___, including ___marmots___, in various areas including Central Asia, Kurdistan, Western Asia, Northern India and ___Uganda___. ___Nestorian___ graves dating to 1338–39 near ___Lake___ ___Issyk___ ___Kul___ in Kyrgyzstan have inscriptions referring to ___plague___ and are thought by many ___epidemiologists___ to mark the ___outbreak___ of the ___epidemic___, from which it could easily have spread to China and India. In ___October___ 2010, ___medical___ ___geneticists___ suggested that all three of the great waves of the ___plague___ originated in ___China___. In ___China___, the 13th century ___Mongol___ conquest caused a decline in ___farming___ and trading. However, economic recovery had been observed at the beginning of the ___14th___ century. In the ___1330s___ a large number of natural disasters and plagues led to widespread ___famine___, starting in ___1331___, with a deadly ___plague___ arriving soon after. ___Epidemics___ that may have included ___plague___ killed an estimated ___25___ ___million___ Chinese and other Asians during the 15 years before it reached ___Constantinople___ in ___1347___.\n",
      "Answers:\n",
      "['Yersinia', 'Nestorian', 'outbreak', 'China', 'Mongol', 'plague', 'Epidemics', 'medical', 'rodents', 'Lake', 'pestis', 'famine', 'farming', 'enzootic', 'epidemiologists', '25', 'epidemic', '1331', 'marmots', 'Uganda', 'Constantinople', '14th', 'million', 'Kul', 'geneticists', '1330s', 'fleas', 'October', '1347', 'Issyk']\n",
      "___Plague___ was reportedly first introduced to ___Europe___ via ___Genoese___ traders at the port city of ___Kaffa___ in the ___Crimea___ in ___1347___. After a protracted ___siege___, during which the ___Mongol___ army under ___Jani___ ___Beg___ was suffering from the ___disease___, the army catapulted the ___infected___ ___corpses___ over the city walls of ___Kaffa___ to infect the inhabitants. The ___Genoese___ traders fled, taking the ___plague___ by ship into ___Sicily___ and the south of Europe, whence it spread north. Whether or not this hypothesis is accurate, it is clear that several existing conditions such as war, ___famine___, and weather contributed to the severity of the ___Black___ ___Death___.\n",
      "Answers:\n",
      "['Europe', 'Death', 'corpses', 'Black', 'Beg', 'Crimea', 'Jani', 'Sicily', 'Mongol', 'disease', 'Kaffa', 'infected', '1347', 'famine', 'plague', 'siege', 'Genoese', 'Plague']\n",
      "From ___Italy___, the disease spread northwest across Europe, striking France, Spain, ___Portugal___ and England by ___June___ ___1348___, then turned and spread east through Germany and Scandinavia from ___1348___ to ___1350___. It was introduced in ___Norway___ in ___1349___ when a ship landed at ___Askøy___, then spread to ___Bjørgvin___ ( modern ___Bergen___ ) and ___Iceland___. Finally it spread to northwestern Russia in ___1351___. The ___plague___ was somewhat less common in parts of Europe that had smaller trade relations with their neighbours, including the Kingdom of ___Poland___, the majority of the ___Basque___ Country, isolated parts of ___Belgium___ and the ___Netherlands___, and isolated alpine villages throughout the continent.\n",
      "Answers:\n",
      "['1351', 'Italy', 'Askøy', '1350', 'Poland', 'Portugal', '1349', 'Bjørgvin', 'Bergen', 'Iceland', 'Basque', 'Belgium', 'Netherlands', 'plague', 'Norway', '1348', 'June']\n",
      "The ___plague___ struck various countries in the Middle East during the ___pandemic___, leading to serious depopulation and permanent change in both economic and social structures. As it spread to western Europe, the disease entered the region from southern Russia also. By ___autumn___ ___1347___, the plague reached ___Alexandria___ in Egypt, probably through the port 's trade with ___Constantinople___, and ports on the ___Black___ ___Sea___. During ___1347___, the disease travelled eastward to ___Gaza___, and north along the eastern coast to cities in Lebanon, Syria and ___Palestine___, including Ashkelon, ___Acre___, Jerusalem, Sidon, Damascus, ___Homs___, and ___Aleppo___. In ___1348–49___, the disease reached ___Antioch___. The city 's residents fled to the north, most of them dying during the journey, but the ___infection___ had been spread to the people of Asia ___Minor.[citation___ needed ]\n",
      "Answers:\n",
      "['Sea', 'Black', 'infection', 'autumn', 'Palestine', 'Homs', 'pandemic', 'Alexandria', '1347', 'Gaza', 'plague', 'Aleppo', 'Antioch', 'Minor.[citation', 'Constantinople', '1348–49', 'Acre']\n",
      "___Gasquet___ ( ___1908___ ) claimed that the Latin name ___atra___ ___mors___ ( ___Black___ Death ) for the 14th - century ___epidemic___ first appeared in modern times in ___1631___ in a book on Danish history by ___J.I.___ ___Pontanus___ : \" ___Vulgo___ & ab effectu atram mortem vocatibant. ( \" Commonly and from its effects, they called it the black death \" ). The name spread through ___Scandinavia___ and then ___Germany___, gradually becoming attached to the mid 14th - century ___epidemic___ as a proper name. In ___England___, it was not until ___1823___ that the ___medieval___ ___epidemic___ was first called the ___Black___ ___Death___.\n",
      "Answers:\n",
      "['Death', 'medieval', 'Vulgo', 'epidemic', 'Black', 'atra', 'J.I.', 'mors', 'England', 'Pontanus', '1823', '1631', 'Gasquet', 'Scandinavia', 'Germany', '1908']\n",
      "Medical knowledge had stagnated during the ___Middle___ ___Ages___. The most authoritative account at the time came from the medical faculty in ___Paris___ in a report to the king of ___France___ that blamed the ___heavens___, in the form of a conjunction of three planets in ___1345___ that caused a \" great ___pestilence___ in the air \". This report became the first and most widely circulated of a series of ___plague___ ___tracts___ that sought to give advice to ___sufferers___. That the ___plague___ was caused by bad air became the most widely accepted theory. Today, this is known as the ___Miasma___ theory. The word ' ___plague___ ' had no special significance at this time, and only the ___recurrence___ of ___outbreaks___ during the ___Middle___ Ages gave it the name that has become the medical term.\n",
      "Answers:\n",
      "['Ages', 'tracts', 'Miasma', 'France', 'Middle', 'recurrence', 'pestilence', 'outbreaks', 'heavens', 'plague', 'Paris', 'sufferers', '1345']\n",
      "The dominant explanation for the ___Black___ ___Death___ is the ___plague___ theory, which attributes the outbreak to ___Yersinia___ ___pestis___, also responsible for an ___epidemic___ that began in southern ___China___ in ___1865___, eventually spreading to ___India___. The investigation of the ___pathogen___ that caused the 19th - century ___plague___ was begun by teams of scientists who visited Hong Kong in ___1894___, among whom was the French - Swiss bacteriologist ___Alexandre___ ___Yersin___, after whom the ___pathogen___ was named ___Yersinia___ ___pestis___. The mechanism by which ___Y.___ ___pestis___ was usually transmitted was established in ___1898___ by Paul - ___Louis___ ___Simond___ and was found to involve the ___bites___ of ___fleas___ whose midguts had become obstructed by ___replicating___ ___Y.___ ___pestis___ several days after feeding on an ___infected___ host. This blockage results in ___starvation___ and aggressive ___feeding___ ___behaviour___ by the ___fleas___, which repeatedly attempt to clear their blockage by ___regurgitation___, resulting in thousands of ___plague___ ___bacteria___ being flushed into the ___feeding___ site, infecting the host. The ___bubonic___ ___plague___ ___mechanism___ was also dependent on two populations of ___rodents___ : one ___resistant___ to the ___disease___, which act as hosts, keeping the ___disease___ ___endemic___, and a second that lack resistance. When the second population dies, the ___fleas___ move on to other hosts, including people, thus creating a human ___epidemic___.\n",
      "Answers:\n",
      "['1865', 'Yersinia', 'behaviour', 'China', 'Alexandre', 'India', 'infected', 'starvation', 'plague', 'regurgitation', 'rodents', 'pestis', 'bites', '1898', 'Death', 'epidemic', 'feeding', 'bubonic', 'mechanism', 'Simond', 'replicating', 'disease', 'endemic', '1894', 'pathogen', 'Louis', 'Black', 'bacteria', 'resistant', 'Yersin', 'fleas', 'Y.']\n",
      "The historian ___Francis___ ___Aidan___ ___Gasquet___ wrote about the ' Great ___Pestilence___ ' in ___1893___ and suggested that \" it would appear to be some form of the ordinary Eastern or ___bubonic___ ___plague___ \". He was able to adopt the ___epidemiology___ of the ___bubonic___ ___plague___ for the ___Black___ Death for the second edition in ___1908___, implicating ___rats___ and ___fleas___ in the process, and his interpretation was widely accepted for other ancient and ___medieval___ ___epidemics___, such as the ___Justinian___ ___plague___ that was prevalent in the Eastern ___Roman___ Empire from ___541___ to ___700___ ___CE___.\n",
      "Answers:\n",
      "['1908', 'epidemiology', 'medieval', 'Aidan', 'CE', 'Black', 'bubonic', 'rats', 'epidemics', '1893', 'Justinian', 'Gasquet', 'fleas', 'plague', '541', 'Roman', '700', 'Pestilence', 'Francis']\n",
      "Other forms of ___plague___ have been implicated by modern scientists. The modern ___bubonic___ ___plague___ has a mortality rate of ___30–75___ % and symptoms including fever of 38–41 ° C ( 100–106 ° F ), headaches, painful aching joints, ___nausea___ and ___vomiting___, and a general feeling of ___malaise___. Left ___untreated___, of those that contract the ___bubonic___ ___plague___, 80 percent die within eight days. ___Pneumonic___ ___plague___ has a mortality rate of 90 to ___95___ percent. Symptoms include ___fever___, ___cough___, and blood - tinged ___sputum___. As the ___disease___ progresses, ___sputum___ becomes free flowing and bright red. ___Septicemic___ ___plague___ is the least common of the three forms, with a mortality rate near 100 %. Symptoms are high fevers and purple ___skin___ ___patches___ ( ___purpura___ due to disseminated ___intravascular___ ___coagulation___ ). In cases of ___pneumonic___ and particularly ___septicemic___ ___plague___, the progress of the ___disease___ is so rapid that there would often be no time for the development of the enlarged ___lymph___ ___nodes___ that were noted as ___buboes___.\n",
      "Answers:\n",
      "['coagulation', 'cough', 'skin', 'purpura', 'malaise', 'untreated', 'fever', '95', 'plague', '30–75', 'sputum', 'Septicemic', 'pneumonic', 'nodes', 'lymph', 'vomiting', 'Pneumonic', 'patches', 'bubonic', 'disease', 'nausea', 'septicemic', 'buboes', 'intravascular']\n",
      "In ___October___ 2010, the open - access scientific journal ___PLoS___ ___Pathogens___ published a paper by a multinational team who undertook a new investigation into the role of ___Yersinia___ ___pestis___ in the Black Death following the disputed identification by Drancourt and ___Raoult___ in ___1998___. They assessed the presence of DNA / RNA with ___Polymerase___ Chain Reaction ( PCR ) techniques for ___Y.___ ___pestis___ from the ___tooth___ ___sockets___ in human ___skeletons___ from mass graves in northern, central and southern Europe that were associated archaeologically with the ___Black___ ___Death___ and subsequent resurgences. The authors concluded that this new research, together with prior analyses from the south of ___France___ and ___Germany___, \"... ends the debate about the etiology of the ___Black___ ___Death___, and unambiguously demonstrates that ___Y.___ ___pestis___ was the causative agent of the ___epidemic___ ___plague___ that devastated Europe during the ___Middle___ ___Ages___ \".\n",
      "Answers:\n",
      "['Ages', 'Death', 'France', 'Yersinia', 'sockets', 'Black', 'epidemic', 'plague', 'Middle', 'tooth', 'pestis', 'Y.', 'Germany', 'October', 'Raoult', 'Pathogens', '1998', 'skeletons', 'PLoS', 'Polymerase']\n",
      "The study also found that there were two previously unknown but related ___clades___ ( ___genetic___ ___branches___ ) of the ___Y.___ ___pestis___ ___genome___ associated with medieval mass graves. These ___clades___ ( which are thought to be extinct ) were found to be ancestral to modern isolates of the modern Y. ___pestis___ strains Y. p. orientalis and Y. p. medievalis, suggesting the ___plague___ may have entered Europe in two waves. Surveys of ___plague___ pit remains in ___France___ and England indicate the first variant entered Europe through the port of ___Marseille___ around November ___1347___ and spread through France over the next two years, eventually reaching ___England___ in the spring of ___1349___, where it spread through the country in three ___epidemics___. Surveys of ___plague___ pit remains from the Dutch town of ___Bergen___ op Zoom showed the ___Y.___ ___pestis___ genotype responsible for the pandemic that spread through the Low Countries from ___1350___ differed from that found in Britain and ___France___, implying ___Bergen___ ___op___ ___Zoom___ ( and possibly other parts of the southern ___Netherlands___ ) was not directly infected from ___England___ or ___France___ in ___1349___ and suggesting a second wave of ___plague___, different from those in Britain and ___France___, may have been carried to the Low Countries from Norway, the ___Hanseatic___ cities or another site.\n",
      "Answers:\n",
      "['genome', 'France', 'plague', 'Zoom', 'clades', 'England', 'epidemics', '1350', 'pestis', '1349', 'genetic', 'Bergen', 'op', 'Netherlands', '1347', 'Hanseatic', 'Y.', 'branches', 'Marseille']\n",
      "The results of the ___Haensch___ study have since been confirmed and amended. Based on genetic evidence derived from ___Black___ Death victims in the East ___Smithfield___ burial site in England, ___Schuenemann___ et al. concluded in ___2011___ \" that the ___Black___ Death in medieval Europe was caused by a variant of ___Y.___ ___pestis___ that may no longer exist. \" A study published in ___Nature___ in ___October___ 2011 sequenced the ___genome___ of ___Y.___ ___pestis___ from plague victims and indicated that the strain that caused the ___Black___ ___Death___ is ancestral to most modern strains of the ___disease___.\n",
      "Answers:\n",
      "['Death', 'Nature', 'genome', 'Black', 'Schuenemann', 'Smithfield', 'Y.', 'pestis', 'disease', 'October', '2011', 'Haensch']\n",
      "The ___plague___ theory was first significantly challenged by the work of British bacteriologist J. F. D. Shrewsbury in ___1970___, who noted that the reported rates of ___mortality___ in rural areas during the 14th - century ___pandemic___ were inconsistent with the modern ___bubonic___ ___plague___, leading him to conclude that contemporary accounts were exaggerations. In 1984 ___zoologist___ ___Graham___ ___Twigg___ produced the first major work to challenge the ___bubonic___ ___plague___ theory directly, and his doubts about the identity of the ___Black___ ___Death___ have been taken up by a number of authors, including Samuel K. ___Cohn___, ___Jr.___ ( 2002 ), David ___Herlihy___ ( 1997 ), and Susan Scott and Christopher ___Duncan___ ( 2001 ).\n",
      "Answers:\n",
      "['Death', 'Black', 'bubonic', 'Duncan', 'zoologist', 'Twigg', 'Cohn', 'pandemic', 'Jr.', 'Herlihy', 'plague', '1970', 'mortality', 'Graham']\n",
      "It is recognised that an ___epidemiological___ account of the ___plague___ is as important as an identification of ___symptoms___, but researchers are hampered by the lack of reliable statistics from this period. Most work has been done on the spread of the ___plague___ in ___England___, and even estimates of overall population at the start vary by over 100 % as no census was undertaken between the time of publication of the ___Domesday___ ___Book___ and the year ___1377___. Estimates of ___plague___ victims are usually extrapolated from figures from the clergy.\n",
      "Answers:\n",
      "['England', '1377', 'epidemiological', 'plague', 'symptoms', 'Book', 'Domesday']\n",
      "In addition to arguing that the ___rat___ population was insufficient to account for a ___bubonic___ ___plague___ ___pandemic___, sceptics of the ___bubonic___ ___plague___ theory point out that the symptoms of the ___Black___ ___Death___ are not unique ( and arguably in some accounts may differ from ___bubonic___ ___plague___ ); that transference via ___fleas___ in goods was likely to be of marginal significance; and that the DNA results may be flawed and might not have been repeated elsewhere, despite extensive samples from other mass graves. Other arguments include the lack of accounts of the death of ___rats___ before ___outbreaks___ of ___plague___ between the 14th and ___17th___ centuries; temperatures that are too cold in northern Europe for the survival of ___fleas___; that, despite primitive transport systems, the spread of the ___Black___ ___Death___ was much faster than that of modern ___bubonic___ ___plague___; that mortality rates of the ___Black___ ___Death___ appear to be very high; that, while modern ___bubonic___ ___plague___ is largely ___endemic___ as a rural ___disease___, the Black Death indiscriminately struck urban and rural areas; and that the pattern of the ___Black___ ___Death___, with major outbreaks in the same areas separated by 5 to ___15___ years, differs from modern ___bubonic___ ___plague___ — which often becomes ___endemic___ for decades with annual flare - ups.\n",
      "Answers:\n",
      "['Death', '15', 'Black', 'bubonic', 'rats', 'pandemic', 'outbreaks', 'disease', 'endemic', 'fleas', 'plague', '17th', 'rat']\n",
      "A variety of alternatives to the ___Y.___ ___pestis___ have been put forward. ___Twigg___ suggested that the cause was a form of ___anthrax___, and ___Norman___ ___Cantor___ ( 2001 ) thought it may have been a combination of ___anthrax___ and other ___pandemics___. ___Scott___ and ___Duncan___ have argued that the ___pandemic___ was a form of ___infectious___ ___disease___ that ___characterise___ as ___hemorrhagic___ ___plague___ similar to ___Ebola___. ___Archaeologist___ ___Barney___ ___Sloane___ has argued that there is insufficient evidence of the ___extinction___ of a large number of ___rats___ in the archaeological record of the medieval ___waterfront___ in ___London___ and that the ___plague___ spread too quickly to support the thesis that the ___Y.___ ___pestis___ was spread from ___fleas___ on ___rats___; he argues that transmission must have been person to person. However, no single alternative solution has achieved widespread acceptance. Many scholars arguing for the ___Y.___ ___pestis___ as the major agent of the ___pandemic___ suggest that its extent and symptoms can be explained by a combination of ___bubonic___ ___plague___ with other ___diseases___, including ___typhus___, ___smallpox___ and ___respiratory___ ___infections___. In addition to the ___bubonic___ ___infection___, others point to additional ___septicemic___ ( a type of \" ___blood___ ___poisoning___ \" ) and ___pneumonic___ ( an ___airborne___ ___plague___ that attacks the ___lungs___ before the rest of the body ) forms of the ___plague___, which lengthen the duration of ___outbreaks___ throughout the seasons and help account for its high mortality rate and additional recorded ___symptoms___. In ___2014___, scientists with Public Health England announced the results of an examination of ___25___ bodies exhumed from the ___Clerkenwell___ area of ___London___, as well as of ___wills___ registered in ___London___ during the period, which supported the ___pneumonic___ hypothesis.\n",
      "Answers:\n",
      "['Sloane', 'diseases', 'smallpox', 'Duncan', 'infectious', 'anthrax', 'rats', 'respiratory', 'characterise', 'airborne', 'wills', 'outbreaks', 'plague', 'blood', 'symptoms', '2014', 'lungs', 'pneumonic', 'infection', 'pestis', 'pandemics', 'poisoning', 'Barney', 'infections', '25', 'bubonic', 'Twigg', 'pandemic', 'disease', 'Norman', 'septicemic', 'London', 'waterfront', 'typhus', 'Clerkenwell', 'Ebola', 'Archaeologist', 'hemorrhagic', 'extinction', 'Scott', 'fleas', 'Y.', 'Cantor']\n",
      "The most widely accepted estimate for the Middle East, including Iraq, Iran and Syria, during this time, is for a death rate of about a third. The ___Black___ Death killed about 40 % of Egypt 's population. Half of ___Paris___ 's population of ___100,000___ people died. In ___Italy___, the population of ___Florence___ was reduced from ___110–120___ ___thousand___ inhabitants in ___1338___ down to 50 thousand in ___1351___. At least 60 % of the population of ___Hamburg___ and ___Bremen___ perished, and a similar percentage of ___Londoners___ may have died from the ___disease___ as well. Interestingly while contemporary reports account of mass ___burial___ ___pits___ being created in response to the large numbers of dead, recent scientific investigations of a burial ___pit___ in ___Central___ ___London___ found well - preserved individuals to be buried in isolated, evenly ___spaced___ graves, suggesting at least some pre - planning and Christian burials at this time. Before ___1350___, there were about ___170,000___ settlements in ___Germany___, and this was reduced by nearly ___40,000___ by ___1450___. In ___1348___, the ___plague___ spread so rapidly that before any physicians or government authorities had time to reflect upon its origins, about a third of the European population had already perished. In crowded cities, it was not uncommon for as much as ___50___ % of the population to die. The ___disease___ bypassed some areas, and the most isolated areas were less vulnerable to ___contagion___. ___Monks___ and priests were especially hard hit since they cared for victims of the ___Black___ ___Death___.\n",
      "Answers:\n",
      "['100,000', 'pits', 'Londoners', 'Monks', 'plague', '1450', 'contagion', '110–120', 'thousand', 'burial', 'spaced', '40,000', '1348', 'Death', '170,000', 'Italy', '1350', 'Central', 'disease', 'Hamburg', 'Germany', 'London', '1351', 'Bremen', 'Black', '1338', 'Florence', 'Paris', '50', 'pit']\n",
      "The ___plague___ repeatedly returned to haunt Europe and the ___Mediterranean___ throughout the 14th to ___17th___ centuries. According to ___Biraben___, the ___plague___ was present somewhere in Europe in every year between ___1346___ and ___1671___. The Second ___Pandemic___ was particularly widespread in the following years : ___1360–63___; ___1374___; 1400; 1438–39; 1456–57; 1464–66; 1481–85; 1500–03; 1518–31; 1544–48; 1563–66; 1573–88; 1596–99; 1602–11; 1623–40; ___1644–54___; and 1664–67. Subsequent ___outbreaks___, though severe, marked the retreat from most of ___Europe___ ( 18th century ) and northern ___Africa___ ( 19th century ). According to ___Geoffrey___ ___Parker___, \" ___France___ alone lost almost a ___million___ people to the ___plague___ in the epidemic of ___1628–31___. \"\n",
      "Answers:\n",
      "['Parker', 'Europe', 'million', 'France', '1346', 'Pandemic', '1644–54', '1374', 'Geoffrey', '1671', 'Biraben', 'outbreaks', 'Mediterranean', 'plague', '17th', '1628–31', '1360–63', 'Africa']\n",
      "In ___England___, in the absence of census figures, historians propose a range of preincident population figures from as high as ___7___ ___million___ to as low as ___4___ ___million___ in ___1300___, and a postincident population figure as low as ___2___ ___million___. By the end of ___1350___, the ___Black___ Death subsided, but it never really died out in ___England___. Over the next few ___hundred___ years, further outbreaks occurred in ___1361–62___, ___1369___, ___1379–83___, ___1389–93___, and throughout the first half of the ___15th___ century. An ___outbreak___ in ___1471___ took as much as ___10–15___ % of the population, while the death rate of the ___plague___ of ___1479–80___ could have been as high as ___20___ %. The most general outbreaks in ___Tudor___ and ___Stuart___ England seem to have begun in ___1498___, ___1535___, ___1543___, ___1563___, ___1589___, ___1603___, ___1625___, and ___1636___, and ended with the Great ___Plague___ of London in ___1665___.\n",
      "Answers:\n",
      "['7', '1379–83', '1471', 'outbreak', '1563', 'Tudor', 'plague', '1498', 'Stuart', '1636', '1361–62', '1300', '1479–80', 'Plague', '2', '1389–93', '15th', 'England', '1350', '1543', '1625', 'hundred', '4', 'million', '1369', 'Black', '20', '10–15', '1603', '1665', '1535', '1589']\n",
      "In ___1466___, perhaps ___40,000___ people died of the ___plague___ in ___Paris___. During the ___16th___ and ___17th___ centuries, the ___plague___ was present in ___Paris___ around 30 per cent of the time. The ___Black___ Death ravaged Europe for three years before it continued on into ___Russia___, where the ___disease___ was present somewhere in the country 25 times between ___1350___ to ___1490___. ___Plague___ ___epidemics___ ravaged London in ___1563___, ___1593___, ___1603___, ___1625___, ___1636___, and ___1665___, reducing its population by 10 to 30 % during those years. Over 10 % of ___Amsterdam___ 's population died in ___1623–25___, and again in ___1635–36___, ___1655___, and ___1664___. ___Plague___ occurred in ___Venice___ 22 times between ___1361___ and ___1528___. The plague of ___1576–77___ killed ___50,000___ in ___Venice___, almost a third of the population. Late outbreaks in central Europe included the ___Italian___ ___Plague___ of ___1629–1631___, which is associated with troop movements during the ___Thirty___ Years ' War, and the Great ___Plague___ of ___Vienna___ in ___1679___. Over 60 % of ___Norway___ 's population died in ___1348–50___. The last ___plague___ outbreak ravaged ___Oslo___ in ___1654___.\n",
      "Answers:\n",
      "['1563', 'Venice', '1466', 'epidemics', '1348–50', '1635–36', '16th', '1654', '1655', '1490', 'plague', '1679', '1576–77', '1636', '1664', '1361', '40,000', 'Plague', '1593', 'Italian', '1629–1631', 'Vienna', '1350', 'disease', '1625', 'Russia', '50,000', 'Oslo', '1528', '1623–25', 'Black', 'Amsterdam', 'Thirty', 'Norway', '1603', '1665', 'Paris', '17th']\n",
      "In the first half of the ___17th___ century, a ___plague___ claimed some ___1.7___ ___million___ victims in Italy, or about 14 % of the population. In ___1656___, the ___plague___ killed about half of ___Naples___ ' ___300,000___ inhabitants. More than ___1.25___ ___million___ deaths resulted from the extreme incidence of ___plague___ in 17th - century Spain. The ___plague___ of ___1649___ probably reduced the population of ___Seville___ by half. In ___1709–13___, a ___plague___ ___epidemic___ that followed the Great Northern War ( ___1700–21___, Sweden v. Russia and allies ) killed about ___100,000___ in Sweden, and ___300,000___ in ___Prussia___. The ___plague___ killed two - thirds of the inhabitants of ___Helsinki___, and claimed a third of ___Stockholm___ 's population. Europe 's last major epidemic occurred in ___1720___ in ___Marseille___.\n",
      "Answers:\n",
      "['1700–21', 'Helsinki', 'million', '1649', 'Stockholm', 'epidemic', 'Marseille', '1720', 'Prussia', '1.7', '1709–13', 'Seville', '100,000', 'Naples', 'plague', '17th', '1.25', '1656', '300,000']\n",
      "The ___Black___ Death ravaged much of the Islamic world. ___Plague___ was present in at least one location in the Islamic world virtually every year between ___1500___ and ___1850___. ___Plague___ repeatedly struck the cities of North Africa. Algiers lost 30 to ___50___ ___thousand___ inhabitants to it in ___1620–21___, and again in ___1654–57___, ___1665___, ___1691___, and ___1740–42___. ___Plague___ remained a major event in ___Ottoman___ ___society___ until the second quarter of the 19th century. Between ___1701___ and ___1750___, thirty - seven larger and smaller ___epidemics___ were recorded in ___Constantinople___, and an additional thirty - one between ___1751___ and ___1800___. Baghdad has suffered severely from ___visitations___ of the ___plague___, and sometimes two - thirds of its population has been wiped out.\n",
      "Answers:\n",
      "['1850', 'society', 'epidemics', '1751', '1654–57', 'plague', 'visitations', '1620–21', '50', 'thousand', 'Plague', '1740–42', 'Ottoman', '1500', 'Constantinople', '1750', 'Black', '1665', '1701', '1800', '1691']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('--------------- MY MODEL ---------------')\n",
    "# Pull out sample paragraph\n",
    "for p in arts[ind_ex_dev]['paragraphs']:\n",
    "    # # Print all AllenNLP classifications\n",
    "    # print([(a,b) for a,b in zip(p['allenNER']['words'].split(), p['allenNER']['tags'].split())])\n",
    "\n",
    "    # AllenNLP results\n",
    "    words = p['allenNER']['words'].split()\n",
    "    # tags = p['allenNER']['tags'].split()\n",
    "    # tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "    tags = p['blank_classified_allen']\n",
    "\n",
    "    # Ground truth\n",
    "    blank_classification = p['blank_classification']\n",
    "\n",
    "    words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "    words_blanked_allen = words2words_blanked(words,tags)\n",
    "    words_hash_ground_truth = words2words_hashblank(words,blank_classification)\n",
    "    words_hash_allen = words2words_hashblank(words,tags)\n",
    "    \n",
    "    # Blanked text\n",
    "    print(words2text(words_hash_allen))\n",
    "\n",
    "    # Answers    \n",
    "    myanswers = list(set(words2answers(words,tags)))\n",
    "    print(\"Answers:\")\n",
    "    print(myanswers)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All articles - compare blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stuff\n",
    "TPR0 = []\n",
    "FPR0 = []\n",
    "ACC0 = []\n",
    "Nsentences0 = []\n",
    "TP0 = []\n",
    "FP0 = []\n",
    "FN0 = []\n",
    "TN0 = []\n",
    "TPpersent0 = []\n",
    "FPpersent0 = []\n",
    "abads = []            # Article-level bads\n",
    "sbc0 = []\n",
    "st0 = []\n",
    "Nwords0 = []\n",
    "\n",
    "art = arts[:]\n",
    "\n",
    "i=-1\n",
    "for a in art:\n",
    "    i=i+1\n",
    "    # AllenNLP results\n",
    "    words = [w for p in a['paragraphs'] for w in p['allenNER']['words'].split()]\n",
    "#     tags = [t for p in a['paragraphs'] for t in p['allenNER']['tags'].split()]\n",
    "#     tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "    tags = [t for p in a['paragraphs'] for t in p['blank_classified_allen']]\n",
    "\n",
    "    # Ground truth\n",
    "    blank_classification = [bc for p in a['paragraphs'] for bc in p['blank_classification']]\n",
    "    blank_classification = [b == 1 for b in blank_classification] # Convert to binary\n",
    "\n",
    "    Nsentences2 = len(text2sentences(words2text(words)))\n",
    "\n",
    "    sbc = sum(blank_classification)\n",
    "    st = sum(tags)\n",
    "    if sbc == 0 or st == 0:\n",
    "        print(\"Warning article {} contains {} ground truth blanks and {} tags. Likely bad\".format(str(i),str(sbc),str(st)))\n",
    "\n",
    "        # Make up some dummy values so don't confuse for a REAL outlier in plots. Should just drop this data in the future\n",
    "        # This is ok because we'll skip them later if want to do stats - that's what abads is for\n",
    "        TPR = 0.0\n",
    "        FPR = 0.0\n",
    "        ACC = 0.0\n",
    "        TP = 100\n",
    "        FP = 100\n",
    "        FN = 100\n",
    "        TN = 100\n",
    "\n",
    "        TPpersent = 1\n",
    "        FPpersent = 1\n",
    "        abads.append(i)\n",
    "    else:\n",
    "        TP = sum([b and t for b,t in zip(blank_classification,tags)])\n",
    "        FP = sum([not b and t for b,t in zip(blank_classification,tags)])\n",
    "        FN = sum([b and not t for b,t in zip(blank_classification,tags)])\n",
    "        TN = sum([not b and not t for b,t in zip(blank_classification,tags)])\n",
    "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "        ACC2 = sum([b == t for b,t in zip(blank_classification,tags)]) / len(tags)\n",
    "\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = TP/(TP+FN)\n",
    "        # Specificity or true negative rate\n",
    "        TNR = TN/(TN+FP)\n",
    "        # Precision or positive predictive value\n",
    "        PPV = TP/(TP+FP)\n",
    "        # Negative predictive value\n",
    "        NPV = TN/(TN+FN)\n",
    "        # Fall out or false positive rate\n",
    "        FPR = FP/(FP+TN)\n",
    "        # False negative rate\n",
    "        FNR = FN/(TP+FN)\n",
    "        # False discovery rate\n",
    "        FDR = FP/(TP+FP)\n",
    "\n",
    "        # Per sententance values\n",
    "        TPpersent = TP / Nsentences2\n",
    "        FPpersent = FP / Nsentences2\n",
    "\n",
    "    TPR0.append(TPR)\n",
    "    FPR0.append(FPR)\n",
    "    ACC0.append(ACC)\n",
    "    TP0.append(TP)\n",
    "    FP0.append(FP)\n",
    "    FN0.append(FN)\n",
    "    TN0.append(TN)\n",
    "    TPpersent0.append(TPpersent)\n",
    "    FPpersent0.append(FPpersent)\n",
    "    sbc0.append(sbc)\n",
    "    st0.append(st)\n",
    "    Nwords0.append(len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tiles of bad articles\n",
    "for ab in abads:\n",
    "    print(art[ab]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how this affects Ntrain / Ndev\n",
    "Ntrain_bad = len([b for b in abads if b < Ntrain])\n",
    "Ndev_bad = len([b for b in abads if b >= Ntrain])\n",
    "print('Ntrain={}'.format(str(Ntrain)))\n",
    "print('Ndev={}'.format(str(Ndev)))\n",
    "print('Ntrain_bad={}'.format(str(Ntrain_bad)))\n",
    "print('Ndev_bad={}'.format(str(Ndev_bad)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = TPR0\n",
    "varname = 'TPR'\n",
    "\n",
    "# Plot bargraph\n",
    "plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{} per article'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrain-Ntrain_bad,Ndev-Ndev_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "set(ax['ax1'].set_xlim(0,1));\n",
    "set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = FPR0\n",
    "varname = 'FPR'\n",
    "\n",
    "# Plot bargraph\n",
    "plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{} per article'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# REdefine for plotting with with more decimal places\n",
    "def plothist_train_dev2(myvar,Ntrain,Ndev,xlabel='value',ylabel='N Articles',devbins=30):\n",
    "    # Import fig stuff\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.pyplot import figure\n",
    "    import statistics\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=False,figsize=(15, 4));\n",
    "    ax1.hist(myvar[0:Ntrain-1], bins=30);  # arguments are passed to np.histogram\n",
    "    ax1.set_title(\"Narticles={}, median={}, mean={}\".format(str(Ntrain),'{0:.4f}'.format(statistics.median(myvar[0:Ntrain-1])),'{0:.2f}'.format(statistics.mean(myvar[0:Ntrain-1]))));\n",
    "    ax1.set_ylabel('N Articles');\n",
    "    ax1.set_xlabel(xlabel);\n",
    "\n",
    "    ax2.hist(myvar[Ntrain:], bins=devbins);  # arguments are passed to np.histogram\n",
    "    ax2.set_title(\"Narticles={}, median={}, mean={}\".format(str(Ndev),'{0:.4f}'.format(statistics.median(myvar[Ntrain:])),'{0:.2f}'.format(statistics.mean(myvar[Ntrain:]))));\n",
    "    ax2.set_xlabel(xlabel);\n",
    "    return {'ax1': ax1, 'ax2':ax2}\n",
    "\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrain-Ntrain_bad,Ndev-Ndev_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "ax = plothist_train_dev2(myvar,Ntrain,Ndev,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "# set(ax['ax1'].set_xlim(0,1));\n",
    "# set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = ACC0\n",
    "varname = 'Accuracy'\n",
    "\n",
    "# Plot bargraph\n",
    "plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{} per article'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrain-Ntrain_bad,Ndev-Ndev_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "set(ax['ax1'].set_xlim(0,1));\n",
    "set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot True positives per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = TPpersent0\n",
    "varname = 'True positives per sentence'\n",
    "\n",
    "# Plot bargraph\n",
    "plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{}'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrain-Ntrain_bad,Ndev-Ndev_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "# set(ax['ax1'].set_xlim(0,1));\n",
    "# set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot False positives per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = FPpersent0\n",
    "varname = 'False positives per sentence'\n",
    "\n",
    "# Plot bargraph\n",
    "plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{}'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrain-Ntrain_bad,Ndev-Ndev_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "# set(ax['ax1'].set_xlim(0,1));\n",
    "# set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find articles containing a lot of true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inds of all articles >0.4 TPR\n",
    "inds = [i for i,x in enumerate(TPR0) if x >=0.08]\n",
    "\n",
    "# Inds of all articles >0.4 TPR and in dev dataset\n",
    "inds = [i for i,x in enumerate(TPR0) if x >=0.08 and x < 1.0 and i > Ntrain and i not in abads]\n",
    "\n",
    "print(len(inds))\n",
    "chosen_ind = inds[0]\n",
    "print('Article #{}'.format(str(i)))\n",
    "print(arts[chosen_ind]['title'])\n",
    "print('True positive rate: {}'.format(str(TPR0[chosen_ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out sample paragraph\n",
    "a = arts[chosen_ind]\n",
    "print(a['title'])\n",
    "\n",
    "# AllenNLP results\n",
    "words = [w for p in a['paragraphs'] for w in p['allenNER']['words'].split()]\n",
    "# tags = [t for p in a['paragraphs'] for t in p['allenNER']['tags'].split()]\n",
    "# tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "tags = [t for p in a['paragraphs'] for t in p['blank_classified_allen']]\n",
    "\n",
    "# Ground truth\n",
    "blank_classification = [bc for p in a['paragraphs'] for bc in p['blank_classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side compare\n",
    "\n",
    "words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "words_blanked_allen = words2words_blanked(words,tags)\n",
    "\n",
    "N=len(words_blanked_ground_truth)\n",
    "N=20\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "print(\"Ground truth\" + '\\t\\t\\t' + \"Prediction\")\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "for c,w in zip(words_blanked_ground_truth[:N],words_blanked_allen[:N]):\n",
    "    print(c + '\\t\\t\\t\\t' + w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blanked text\n",
    "# print(words2text(words_blanked_ground_truth))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,blank_classification)\n",
    "print(\"Answers:\")\n",
    "print(set(myanswers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blanked text\n",
    "# print(words2text(words_blanked_allen))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,tags)\n",
    "print(\"Answers:\")\n",
    "print(set(myanswers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All paragraphs - compare blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stuff\n",
    "TPR0 = []\n",
    "FPR0 = []\n",
    "ACC0 = []\n",
    "Nsentences0 = []\n",
    "TP0 = []\n",
    "FP0 = []\n",
    "FN0 = []\n",
    "TN0 = []\n",
    "TPpersent0 = []\n",
    "FPpersent0 = []\n",
    "abads = []\n",
    "indices = {'i':[],'j':[],'k':[]}\n",
    "\n",
    "art = arts[:]\n",
    "\n",
    "\n",
    "# Only track true positives and false positive to avoid having to deal with other annoying edge cases\n",
    "i=-1\n",
    "k=-1\n",
    "Ntrainp = 0\n",
    "Ndevp=0\n",
    "for a in art:\n",
    "    i=i+1\n",
    "    j=-1\n",
    "    for p in a['paragraphs']:\n",
    "        j=j+1\n",
    "        k=k+1\n",
    "        if i < Ntrain: Ntrainp=Ntrainp+1;\n",
    "        else: Ndevp = Ndevp+1\n",
    "        # AllenNLP results\n",
    "        words = [w for w in p['allenNER']['words'].split()]\n",
    "        tags = [t for t in p['allenNER']['tags'].split()]\n",
    "        tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "\n",
    "        # Ground truth\n",
    "        blank_classification = [bc for bc in p['blank_classification']]\n",
    "        blank_classification = [b == 1 for b in blank_classification] # Convert to binary\n",
    "\n",
    "        Nsentences2 = len(text2sentences(words2text(words)))\n",
    "\n",
    "        sbc = sum(blank_classification)\n",
    "        st = sum(tags)\n",
    "        if sbc == 0:\n",
    "            #print(\"Warning article {}, paragraph P{} contains {} ground truth blanks and {} tags. Likely bad\".format(str(i),str(j),str(sbc),str(st)))\n",
    "\n",
    "            # Make up some dummy values so don't confuse for a REAL outlier in plots. Should just drop this data in the future\n",
    "            # This is ok because we'll skip them later if want to do stats - that's what bads is for\n",
    "            TPR = 0.7\n",
    "            FNR = 0.7\n",
    "            ACC = 0.7\n",
    "            TP = 100\n",
    "            FP = 100\n",
    "            FN = 100\n",
    "            TN = 100\n",
    "            TPpersent = 1\n",
    "            FPpersent = 1\n",
    "            abads.append(k)       # kth paragraph is bad\n",
    "        else:\n",
    "            TP = sum([b and t for b,t in zip(blank_classification,tags)])\n",
    "            FP = sum([not b and t for b,t in zip(blank_classification,tags)])\n",
    "            FN = sum([b and not t for b,t in zip(blank_classification,tags)])\n",
    "            TN = sum([not b and not t for b,t in zip(blank_classification,tags)])\n",
    "#             ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "            ACC = sum([b == t for b,t in zip(blank_classification,tags)]) / len(tags)\n",
    "\n",
    "            # Sensitivity, hit rate, recall, or true positive rate\n",
    "            TPR = TP/(TP+FN)\n",
    "#             # Specificity or true negative rate\n",
    "#             TNR = TN/(TN+FP) \n",
    "#             # Precision or positive predictive value\n",
    "#             PPV = TP/(TP+FP)\n",
    "#             # Negative predictive value\n",
    "#             NPV = TN/(TN+FN)\n",
    "#             # Fall out or false positive rate\n",
    "#             FPR = FP/(FP+TN)\n",
    "            # False negative rate\n",
    "            FNR = FN/(TP+FN)\n",
    "#             # False discovery rate\n",
    "#             FDR = FP/(TP+FP)\n",
    "\n",
    "            # Per sententance values\n",
    "            TPpersent = TP / Nsentences2\n",
    "            FPpersent = FP / Nsentences2\n",
    "    \n",
    "        TPR0.append(TPR)\n",
    "        FPR0.append(FPR)\n",
    "        ACC0.append(ACC)\n",
    "        TP0.append(TP)\n",
    "        FP0.append(FP)\n",
    "        FN0.append(FN)\n",
    "        TN0.append(TN)\n",
    "        TPpersent0.append(TPpersent)\n",
    "        FPpersent0.append(FPpersent)\n",
    "        indices['i'].append(i)\n",
    "        indices['j'].append(j)\n",
    "        indices['k'].append(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR0[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Plot the histogram without containing any bads\n",
    "# Calculate how this affects Ntrain / Ndev\n",
    "Ntrainp_bad = len([b for b in abads if b < Ntrainp])\n",
    "Ndevp_bad = len([b for b in abads if b >= Ntrainp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ntrainp)\n",
    "print(Ndevp)\n",
    "print(Ntrainp_bad)\n",
    "print(Ndevp_bad)\n",
    "max(abads)\n",
    "len(FN0)\n",
    "\n",
    "x = []\n",
    "for a in abads:\n",
    "    x.append(TPR0[a])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar = TPR0\n",
    "varname = 'TPR'\n",
    "\n",
    "# Plot bargraph (Don't plot figure for each paragraph!)\n",
    "# plotbar_train_dev2(myvar,Ntrain,Ndev,ylabel='{}'.format(varname),xlabel='Article #')\n",
    "\n",
    "# # # Plot the histogram without containing any bads\n",
    "# myvar without the bad articles\n",
    "myvar2 = [tp for i, tp in enumerate(myvar) if i not in abads]\n",
    "\n",
    "# Plot the histogram\n",
    "ax = plothist_train_dev2(myvar2,Ntrainp-Ntrainp_bad,Ndevp-Ndevp_bad,xlabel=varname,ylabel='N Articles',devbins='auto')\n",
    "# set(ax['ax1'].set_xlim(0,1));\n",
    "# set(ax['ax2'].set_xlim(0,1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find paragraphs containing a lot of true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inds of all articles >0.4 TPR\n",
    "inds = [i for i,x in enumerate(TPR0) if x >=0.6]\n",
    "\n",
    "# Inds of all articles >0.4 TPR and in dev dataset\n",
    "inds = [i for i,x in enumerate(TPR0) if x >=0.4 and x < 1.0 and i > Ntrainp and i not in abads]\n",
    "\n",
    "print(len(inds))\n",
    "chosen_ind = inds[0]\n",
    "i = indices['i'][chosen_ind]\n",
    "j = indices['j'][chosen_ind]\n",
    "k = indices['k'][chosen_ind]\n",
    "print('Article #{} paragraph #{}'.format(str(i),str(j)))\n",
    "print(arts[i]['title'])\n",
    "print('True positive rate: {}'.format(str(TPR0[chosen_ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out sample paragraph\n",
    "p = arts[i]['paragraphs'][j]\n",
    "\n",
    "# AllenNLP results\n",
    "words = p['allenNER']['words'].split()\n",
    "# tags = p['allenNER']['tags'].split()\n",
    "# tags = [not t == '0' for t in tags]   # Convert to binary\n",
    "tags = p['blank_classified_allen']\n",
    "\n",
    "# Ground truth\n",
    "blank_classification = p['blank_classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side compare\n",
    "\n",
    "words_blanked_ground_truth = words2words_blanked(words,blank_classification)\n",
    "words_blanked_allen = words2words_blanked(words,tags)\n",
    "\n",
    "N=len(words_blanked_ground_truth)\n",
    "N=20\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "print(\"Ground truth\" + '\\t\\t\\t' + \"Prediction\")\n",
    "print(\"============\" + '\\t\\t\\t' + \"==========\")\n",
    "for c,w in zip(words_blanked_ground_truth[:N],words_blanked_allen[:N]):\n",
    "    print(c + '\\t\\t\\t\\t' + w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth blanked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blanked text\n",
    "print(words2text(words_blanked_ground_truth))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,blank_classification)\n",
    "print(\"Answers:\")\n",
    "print(myanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blanked text\n",
    "print(words2text(words_blanked_allen))\n",
    "\n",
    "# Answers    \n",
    "myanswers = words2answers(words,tags)\n",
    "print(\"Answers:\")\n",
    "print(myanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([b and t for b,t in zip(blank_classification,tags)])\n",
    "FP = sum([not b and t for b,t in zip(blank_classification,tags)])\n",
    "FN = sum([b and not t for b,t in zip(blank_classification,tags)])\n",
    "TN = sum([not b and not t for b,t in zip(blank_classification,tags)])\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "ACC2 = sum([b == t for b,t in zip(blank_classification,tags)]) / len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ACC)\n",
    "print(ACC2)\n",
    "print(TP)\n",
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TPR)\n",
    "print(FPR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allennlp]",
   "language": "python",
   "name": "conda-env-allennlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
